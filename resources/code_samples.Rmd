---
title: "code_samples"
author: "Willliam Ofosu Agyapong"
date: "11/22/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r variables-description, echo=F}
table1 <- data.frame(rbind(c("Age", "Age of the patient", "Years", paste("[",min(heart_dat$age),",..., ", max(heart_dat$age),"]")),
                           c("Anaemia","Decrease of red blood cells or hemoglobin","Binary", "0, 1"), 
                           c("High blood pressure (HBP)", "If a patient has diabetes", "Binary", "0, 1"), 
                           c("Creatinine phosphokinase (CPK)", "Level of the CPK enzyme in the blood", "mcg/L", paste("[", min(heart_dat$CPK),",...,", max(heart_dat$CPK),"]")), 
                           c("Diabetes", "If the patient has diabetes", "Binary", "0, 1"),
                           c("Ejection fraction", "Percentage of blood leaving the heart at each contraction", "Percentage", paste("[", min(heart_dat$ejection_frac),",...,", max(heart_dat$ejection_frac),"]")),
                           c("Sex", "Woman or man", "Binary", "0, 1"), 
                           c("Platelets", "Platelets in the blood", "kiloplatelets/mL", paste("[", min(heart_dat$platelets),",...,", max(heart_dat$platelets),"]")),
                           c("Serum creatinine", "Level of creatinine in the blood", "mg/dL", paste("[", min(heart_dat$serum_creatinine),",...,", max(heart_dat$serum_creatinine),"]")), 
                           c("Serum sodium", "Level of sodium in the blood", "mEq/L", paste("[", min(heart_dat$serum_sodium),",...,", max(heart_dat$serum_sodium),"]")), 
                           c("Smoking", "If the patient smokes", "Binary", "0, 1"), 
                           c("Time", "Follow-up period", "Days", paste("[", min(heart_dat$time),",...,", max(heart_dat$time),"]")),
                           c("Death event", "If the patient died during the follow-up period", "Binary", "0, 1")))
names(table1) <- c("Variable Name", "Description", "Measurement Unit", "Range")

kable(table1, caption = "Table 1: Variables in the heart failure data set")%>%
       kable_paper("hover", full_width = F)%>% 
       kable_styling(font_size = 12)
```






```{r}
#------ Model building -----------
# Create a wrapper function to abstract away the common aspects of model fitting
fit.model <- function(method, tunegrid="", data=NULL, formula=NULL) {
  
  data <- train_set
  if(is.null(formula)) formula <- death_event ~. -time
      
  # Train the model
   train(
           formula,
           data = data,
           method = method,
           trControl = trainControl(method = "cv", 5),
           preProcess = c("center","scale"),
           tuneGrid = tunegrid)
}


# Logistic Regression
log <-  train(death_event ~ .-time,
                 data=train_set,
                 method="glm",
                 family = binomial(link = "logit"),
                trControl = trainControl(method = "cv", 5),
                preProcess = c("center", "scale")) 

# KNN
knn <- fit.model("knn", data.frame(k=1:10))

# LDA
lda <- train(death_event ~ .,
                 data=train_set,
                 method="lda",
                trControl = trainControl(method = "cv", 5),
                preProcess = c("center", "scale"))

#-------------- Elastic Net Models -------------------
# fit a LASSO model
lasso <- fit.model("glmnet", expand.grid(.alpha=1, .lambda=seq(0,0.1,0.01)))

# Fit a Ridge regression model
ridge <- fit.model("glmnet", expand.grid(.alpha=0, .lambda=seq(0,0.1,0.01)))


# Bagging
# bag <- fit.model("rf", data.frame(mtry=11))
bag <- train(death_event ~ .-time,
                 data=train_set,
                 method="rf",
                trControl = trainControl(method = "cv", 5),
                preProcess = c("center", "scale"),
                tuneGrid = data.frame(mtry=11),
                ntree = 1000) 


# Random Forest
# rf <- fit.model("rf", data.frame(mtry=1:10))
rf <- train(death_event ~ .-time,
                 data=train_set,
                 method="rf",
                trControl = trainControl(method = "cv", 5),
                preProcess = c("center", "scale"),
                tuneGrid = data.frame(mtry=1:10),
                ntree = 1000) 

#-------------- 

# Support Vector Machine with polynomial kernel
svc <- fit.model("svmLinear", data.frame(C=c(0.1,0.2, 1,1.4, 1.6, 10)))

# SVM with polynomial kernel
svmP <- fit.model("svmPoly", expand.grid(C=c(0.1,0.2, 1, 1.4, 1.6, 10),
                                 degree=2:5,
                                 scale=1))

# Support Vector Machine with radial kernel
svmR <- fit.model("svmRadial", expand.grid(C=c(0.1,0.2, 1,1.4, 1.6, 10),                                 sigma=c(0.01, 0.05,0.1,0.5,1)))
```

```{r echo=FALSE}
# Create a custom confusion matrix with performance metrics
metrics <- function(model_object, test_data=NULL) {
  if(is.null(test_data)) test_data <- test_set
  
  prediction <- predict(model_object, test_data) 
  target <- test_data$death_event
  
  tbl <- table(prediction, target)
  tbl_new <- as.data.frame(tbl)
  colnames(tbl_new) <- c("Predicted","Actual", "Freq")
  
  # Compute performance metrics
  freq <- tbl_new$Freq
  accuracy <- (freq[1]+freq[4])/(sum(freq)) # correct classification rate
  sensi <- freq[4]/sum(freq[3:4])  # sensitivity
  speci <- freq[1]/sum(freq[1:2])  # specificity
  ppv <-  freq[4]/(freq[2]+freq[4]) # Positive Predictive Value
  npv <- freq[1]/(freq[1]+freq[3]) # Positive Predictive Value
 # Returned outputs
 return(list(
   accuracy = round(accuracy*100, 3),
   mcr = round((1-accuracy)*100,2),
   sens = sensi,
   spec = speci,
   ppv = ppv,
   npv = npv,
   confMat = tbl,
   confMat2 = tbl_new
 ))
}
```



```{r echo=FALSE}

#------- Compute performance metrics for the full models ---------------
log.metric <- metrics(log)
lda.metric <- metrics(lda)
knn.metric <- metrics(knn)
lasso.metric <- metrics(lasso)
ridge.metric <- metrics(ridge)
bag.metric <- metrics(bag)
rf.metric <- metrics(rf)
svc.metric <- metrics(svc)
svmP.metric <- metrics(svmP)
svmR.metric <- metrics(svmR)

mod.sum <- data.frame(rbind(c("KNN", knn$bestTune$k, rep("-",5),  knn.metric$mcr),
                          c("Logistic Regression", rep("-",6), log.metric$mcr),
                          c("LDA", rep("-",6), lda.metric$mcr),
                          c("LASSO  Regression", "-", lasso$bestTune$lambda, rep("-",4), lasso.metric$mcr),
                          c("Ridge Regression", "-", ridge$bestTune$lambda,rep("-",4), ridge.metric$mcr),
                          c("Bagging", rep("-",6), bag.metric$mcr),
                          c("Random Forest", rep("-",5), rf$bestTune$mtry, rf.metric$mcr),
                          c("SVC", "-","-", svc$bestTune$C, rep("-",3),  svc.metric$mcr),
                          c("SVM (Polynomial Kernel)", "-", "-", svmP$bestTune$C,svmP$bestTune$degree, "-", "-", svmP.metric$mcr),
                          c("SVM (Radial Kernel)", rep("-",2),svmP$bestTune$C, "-", svmR$bestTune$sigma, "-", svmR.metric$mcr)))

names(mod.sum) <- c("Model", "K", "Lambda","Cost", "Degree", "Sigma", "Mtry", "Misclassification Rate (%)")

kable(mod.sum, align = "lccccccc", caption = "Table 4: Results from the full models") %>%
  kable_paper("hover", full_width = F)%>% 
       kable_styling(font_size = 12)

#------- Compute performance metrics for the reduced models ---------------
log2.metric <- metrics(log2)
lda2.metric <- metrics(lda2)
knn2.metric <- metrics(knn2)
lasso2.metric <- metrics(lasso2)
ridge2.metric <- metrics(ridge2)
bag2.metric <- metrics(bag2)
rf2.metric <- metrics(rf2)
svc2.metric <- metrics(svc2)
svmP2.metric <- metrics(svmP2)
svmR2.metric <- metrics(svmR2)

mod2.sum <- data.frame(rbind(c("KNN", knn2$bestTune$k, rep("-",5),  knn2.metric$mcr),
                          c("Logistic Regression", rep("-",6), log2.metric$mcr),
                          c("LDA", rep("-",6), lda2.metric$mcr),
                          c("LASSO  Regression", "-", lasso2$bestTune$lambda, rep("-",4), lasso2.metric$mcr),
                          c("Ridge Regression", "-", ridge2$bestTune$lambda,rep("-",4), ridge2.metric$mcr),
                          c("Bagging", rep("-",6), bag2.metric$mcr),
                          c("Random Forest", rep("-",5), rf2$bestTune$mtry, rf2.metric$mcr),
                          c("SVC", "-","-", svc2$bestTune$C, rep("-",3),  svc2.metric$mcr),
                          c("SVM (Polynomial Kernel)", "-", "-", svmP2$bestTune$C,svmP2$bestTune$degree, "-", "-", svmP2.metric$mcr),
                          c("SVM (Radial Kernel)", rep("-",2),svmP2$bestTune$C, "-", svmR2$bestTune$sigma, "-", svmR2.metric$mcr)))

names(mod2.sum) <- c("Model", "K", "Lambda","Cost", "Degree", "Sigma", "Mtry", "Misclassification Rate (%)")

kable(mod2.sum, align = "lccccccc", caption = "Table 5: Results from the reduced models") %>%
  kable_paper("hover", full_width = F)%>% 
       kable_styling(font_size = 12)
```