---
title: "Predictive modelling"
author: "George, John & William"
date: "11/17/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, echo=F, message=FALSE, warning=FALSE}
source("Packages.R")
```

## Data Preparation and cleaning 
```{r, echo=F,message=FALSE, warning=FALSE, echo= F}
# PREPARATION AND CLEANING

load("FIHI_clean.RData")
data <- FIHI_sub2[,-1]
```

```{r,message=FALSE, warning=FALSE, echo= F}
# obtaining the missing percentage of each variable
missing_rate <- data.frame()
nr <- NROW(data)
nc <- NCOL(data)
Var_name <- variable.names(data)
for (i in 1:nc) {
  na <- sum(is.na(data[,i]))
  na_rate <- (na/nr)*100
  result <- list(Number_Missing = na, Missing_Rate = na_rate, 
                 Variable = Var_name[i])
  missing_rate <- rbind(missing_rate, result, stringsAsFactors = F)
}
head(missing_rate)
```

```{r,message=FALSE, warning=FALSE, echo= F}
library(dplyr)
data_pa<- data %>%
  dplyr::select(-starts_with("FI_"), -ends_with("_changed"), -`college/school`) %>%
  filter(permanent_address != "NA") 
```

19 columns with 5095 observations


```{r,message=FALSE, warning=FALSE, echo= F}
#Missing  value imputation
set.seed(123)
suppressPackageStartupMessages(library(mice))
data_imputed <- mice(data_pa[,-15], printFlag = F)
data_1 <- complete(data_imputed, 1)
data1 <- as.data.frame(data_1)
data_pad<-cbind("permanent_address"=data_pa$permanent_address,data1)
rm(data_imputed, data_1, data1)
```

## missing value treatment
```{r,message=FALSE, warning=FALSE, echo= F}
 #data[is.na(data)] <- 0
data_pad <- data_pad %>%
   mutate(across(everything(), as.factor))
```


```{r,message=FALSE, warning=FALSE, echo= F}
# PARTITION DATA
set.seed(123)
intrain <- createDataPartition(y=1:NROW(data_pad), p= 0.67, list = FALSE)
training <- data_pad[intrain,];  testing <- data_pad[-intrain,]

dim(training) # training data
dim(testing)
```

The training data has 76 observations with 1887 now (old =1057 when compared) variables.
The testing data has 32 observation with 1887 now (old= 1057 when compared) variables.

## SVM with kernlab package with tuned parameters

### Linear SVM through kernlab
```{r, message=FALSE, warning=FALSE, echo= F}
# SVM I: LINEAR  (1)
# ----------------
set.seed(125)
trctrl<- trainControl(method = "repeatedcv", number=10, repeats = 3)
model_linear<-ksvm(permanent_address ~., data = training, kernel = "vanilladot", type= "C-bsvc",
                   trControl=trctrl,  prob.model=T, scale= T,
                   tuneLength = 10)
```

```{r,message=F,echo=F, warning=F}
# PREDICTIONS
# Obtaining Misclassification 
pred.test<- model_linear %>% predict(testing)
conf_mat<-confusionMatrix(pred.test, testing$permanent_address)
tab<- conf_mat$table
misscal_L<- round((1-sum(diag(tab)/sum(tab)))*100,digits = 2)
```

```{r, echo=F, message=F}
## Ploting the AUC 
test_pred_1 <- predict(model_linear, newdata = testing, type= "prob")
ROC_SR <- roc(response=testing$permanent_address, predictor = test_pred_1[, 2])
plot(ROC_SR, col="brown")
AUC_L<-round(ROC_SR$auc, digits=4)  # AUC
text(x=0.4, y=0.25, paste("Area Under Curve = ", AUC_L, sep=""), col="blue", cex=1.2)
```

## Computing SVM using radial basis kernel (rbfdot)
```{r, warning=FALSE, message=FALSE, echo=F}
set.seed(125)
trctrl <- trainControl(method = "repeatedcv", number=4, repeats = 2)
model_Radial <- ksvm(permanent_address ~., data = training, kernel = "rbfdot", type= "C-bsvc",
                   trControl=trctrl,  prob.model=T, scale= T,
                   tuneLength = 10)
```

```{r, echo=F, message=FALSE}
# Obtaining Misclassification 
pred.test_rad <- model_Radial %>% predict(testing)
conf_mat_R<-confusionMatrix(pred.test_rad, testing$permanent_address)
tab_R<- conf_mat_R$table
misscal_R<- round((1-sum(diag(tab_R)/sum(tab_R)))*100,digits = 2)
```

```{r, echo=F, message=FALSE}
test_pred_R <- predict(model_Radial, newdata = testing, type= "prob")
ROC_SR <- roc(response=testing$permanent_address, predictor = test_pred_R[, 2])
plot(ROC_SR, col="brown")
AUC_R<-round(ROC_SR$auc, digits=4)  # AUC
text(x=0.4, y=0.25, paste("Area Under Curve = ", AUC_R, sep=""), col="blue", cex=1.2) 
```

## Computing SVM using polynomial basis kernel
```{r, warning=FALSE,message=FALSE, echo=F}
set.seed(125)
trctrl <- trainControl(method = "repeatedcv", number=4, repeats = 2)
model_Poly <- ksvm(permanent_address ~., data = training, kernel = "polydot", type= "C-bsvc",
                    trControl=trctrl,  prob.model=T, scale= T,
                    tuneLength = 10)
```


```{r, echo=F, message=FALSE}
# Obtaining Misclassification 
pred.test_pol <- model_Poly %>% predict(testing)
conf_mat_P<-confusionMatrix(pred.test_pol, testing$permanent_address)
tab_P<- conf_mat_P$table
misscal_P<- round((1-sum(diag(tab_P)/sum(tab_P)))*100,digits = 2)
```

```{r, echo=F, message=FALSE}
## Ploting the AUC 
test_pred_P <- predict(model_Poly, newdata = testing, type= "prob")
ROC_SR <- roc(response=testing$permanent_address, predictor = test_pred_P[, 2])
plot(ROC_SR, col="brown")
AUC_P<-round(ROC_SR$auc, digits=4)  # AUC
text(x=0.4, y=0.25, paste("Area Under Curve = ", AUC_P, sep=""), col="blue", cex=1.2)
```


## Classification through Decision Trees 

```{r, warning=FALSE, message=FALSE, echo=F}
library(rpart)
library(rpart.plot)
library(tree)
control <- rpart.control(minsplit = 3,
                         minbucket = round(4/ 3),
                         maxdepth = 5,
                         cp = 0)
model_trees<- rpart(permanent_address~., data = training, method = "class", control = control)
```


```{r, echo=F, message=F, warning=FALSE}
# Obtaining Misclassification
pred.test_trees <- predict(model_trees, testing, type= 'class')
conf_mat_T<-confusionMatrix(pred.test_trees, testing$permanent_address)
tab_T<- conf_mat_T$table
misscal_T<- round((1-sum(diag(tab_T)/sum(tab_T)))*100,digits = 2)
```


```{r, echo=F, message=F, warning=FALSE}
## Ploting the AUC 
test_pred_T <- predict(model_trees, newdata = testing, type= "prob")
ROC_SR <- roc(response=testing$permanent_address, predictor = test_pred_T[, 2])
plot(ROC_SR, col="brown")
AUC_T<-round(ROC_SR$auc, digits=4)  # AUC
text(x=0.4, y=0.25, paste("Area Under Curve = ", AUC_T, sep=""), col="blue", cex=1.2)
```

## Classification through Naive Bayes 
```{r,message=FALSE, warning=FALSE, echo= F}
library(naivebayes)
set.seed(125)
model_Naive <- naive_bayes(permanent_address~., data = training, usekernel = T) 
```

```{r,message=FALSE, warning=FALSE, echo= F}
# Obtaining Misclassification
p2 <- predict(model_Naive, testing)
tab_N <- table(p2, testing$permanent_address)
misscal_N<- round((1 - sum(diag(tab_N)) / sum(tab_N))*100,digits = 2)
```

```{r,message=FALSE, warning=FALSE, echo= F}
# Obtaining and graphing AUC
test_pred_N <- predict(model_Naive, newdata = testing, type= "prob")
ROC_SR <- roc(response=testing$permanent_address, predictor = test_pred_N[, 2])
plot(ROC_SR, col="brown")
AUC_N<-round(ROC_SR$auc, digits=4)  # AUC
text(x=0.4, y=0.25, paste("Area Under Curve = ", AUC_N, sep=""), col="blue", cex=1.2) 
```

## Comparison between the kernels base on their AUC and Misclassification 
```{r, echo=F}
Methods<- c("SVM_Linear", "SVM_Radial","SVM_Polynomial","Decision Trees","Naive Bayes")
AUC<- c(AUC_L,AUC_R,AUC_P,AUC_T, AUC_N)
Missclassification<- c(misscal_L,misscal_R,
                       misscal_P,misscal_T, misscal_N)
compare_table<-data.frame(cbind(Methods,AUC,Missclassification))
knitr::kable(compare_table, align = "lcc")
```





------------------------------------------------------------------------------
## Modelling for Spend night elsewhere
-------------------------------------------------------------------------------

```{r,message=FALSE, warning=FALSE, echo= F}
data_ne<- data %>%
  dplyr::select(-starts_with("FI_"), -ends_with("_changed"), -`college/school`) %>%
  filter(spent_night_elsewhere != "NA") 
```


```{r,message=FALSE, warning=FALSE, echo= F}
#Missing  value imputation
set.seed(123)
suppressPackageStartupMessages(library(mice))
data_imputed <- mice(data_ne[,-16], printFlag = F)
data_1 <- complete(data_imputed, 1)
data1 <- as.data.frame(data_1)
data_sne<-cbind("spent_night_elsewhere"=data_ne$spent_night_elsewhere, data1)
rm(data_imputed, data_1, data1)
```

## missing value treatment
```{r,message=FALSE, warning=FALSE, echo= F}
 #data[is.na(data)] <- 0
data_sne <- data_sne %>%
   mutate(across(everything(), as.factor))
```


```{r,message=FALSE, warning=FALSE, echo= F}
# PARTITION DATA
set.seed(123)
intrain <- createDataPartition(y=1:NROW(data_sne), p= 0.67, list = FALSE)
training <- data_sne[intrain,];  testing <- data_sne[-intrain,]

dim(training) # training data
dim(testing)
```
Due to the three levels SVM is not appropriate,  hence 

## Classification through Decision Trees 
```{r, warning=FALSE, message=FALSE, echo=F}
library(rpart)
library(rpart.plot)
library(tree)
control <- rpart.control(minsplit = 3,
                         minbucket = round(4/ 3),
                         maxdepth = 5,
                         cp = 0)
model_trees<- rpart(spent_night_elsewhere~., data = training, method = "class", control = control)
```


```{r, echo=F, message=F, warning=FALSE}
# Obtaining Misclassification
pred.test_trees <- predict(model_trees, testing, type= 'class')
conf_mat_T<-confusionMatrix(pred.test_trees, testing$spent_night_elsewhere)
tab_T<- conf_mat_T$table
misscal_T<- round((1-sum(diag(tab_T)/sum(tab_T)))*100,digits = 2)
```


```{r, echo=F, message=F, warning=FALSE}
## Ploting the AUC 
test_pred_T <- predict(model_trees, newdata = testing, type= "prob")
ROC_SR <- roc(response=testing$spent_night_elsewhere, predictor = test_pred_T[, 2])
plot(ROC_SR, col="brown")
AUC_T<-round(ROC_SR$auc, digits=4)  # AUC
text(x=0.4, y=0.25, paste("Area Under Curve = ", AUC_T, sep=""), col="blue", cex=1.2)
```

## Classification through Naive Bayes 
```{r,message=FALSE, warning=FALSE, echo= F}
library(naivebayes)
set.seed(125)
model_Naive <- naive_bayes(spent_night_elsewhere~., data = training, usekernel = T) 
```

```{r,message=FALSE, warning=FALSE, echo= F}
# Obtaining Misclassification
p2 <- predict(model_Naive, testing)
tab_N <- table(p2, testing$spent_night_elsewhere)
misscal_N<- round((1 - sum(diag(tab_N)) / sum(tab_N))*100, digits = 2)
```

```{r,message=FALSE, warning=FALSE, echo= F}
# Obtaining and graphing AUC
test_pred_N <- predict(model_Naive, newdata = testing, type= "prob")
ROC_SR <- roc(response=testing$spent_night_elsewhere, predictor = test_pred_N[, 2])
plot(ROC_SR, col="brown")
AUC_N<-round(ROC_SR$auc, digits=4)  # AUC
text(x=0.4, y=0.25, paste("Area Under Curve = ", AUC_N, sep=""), col="blue", cex=1.2) 
```

## Comparison between the kernels base on their AUC and Misclassification 
```{r, echo=F}
Methods<- c("Decision Trees","Naive Bayes")
AUC<- c(AUC_T, AUC_N)
Missclassification<- c(misscal_T, misscal_N)
compare_table<-data.frame(cbind(Methods,AUC,Missclassification))
knitr::kable(compare_table, align = "lcc")
```

