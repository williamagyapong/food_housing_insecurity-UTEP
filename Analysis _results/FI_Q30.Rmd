---
title: "Predictive modelling"
author: "George, John & William"
date: "11/17/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, echo=F, message=FALSE, warning=FALSE}
source("Packages.R")
```

## Data Preparation and cleaning 
```{r, echo=F,message=FALSE, warning=FALSE, echo= F}
# PREPARATION AND CLEANING

load("FIHI_clean.RData")
data <- FIHI_sub2[,-1]
```


## Getting the missing values percentages

```{r,message=FALSE, warning=FALSE, echo= F}
# obtaining the missing percentage of each variable
missing_rate <- data.frame()
nr <- NROW(data)
nc <- NCOL(data)
Var_name <- variable.names(data)
for (i in 1:nc) {
  na <- sum(is.na(data[,i]))
  na_rate <- (na/nr)*100
  result <- list(Number_Missing = na, Missing_Rate = na_rate, 
                 Variable = Var_name[i])
  missing_rate <- rbind(missing_rate, result, stringsAsFactors = F)
}
head(missing_rate)
```

```{r,message=FALSE, warning=FALSE, echo= F}
library(dplyr)
data_pa<- data %>%
  rename(college_school = `college/school`) %>%
  dplyr::select(-permanent_address, -spent_night_elsewhere, -ends_with("_changed")) %>%
  filter(FI_q30 != "NA") 

dim(data_pa)
```


## missing value treatment

Method I
```{r,message=FALSE, warning=FALSE, echo= F}
#Missing  value imputation
set.seed(123)
suppressPackageStartupMessages(library(mice))
data_imputed <- mice(data_pa[,-which(names(data_pa)=='FI_q30')], printFlag = F)
data_1 <- complete(data_imputed, 1)
data1 <- as.data.frame(data_1)
data_pad<-cbind("FI_q30"=data_pa$FI_q30,data1)
rm(data_imputed, data_1, data1)
```

# Treating imbalance classification
```{r}
library(ROSE)
 data_pad_balance<-ovun.sample(FI_q30 ~ ., data = data_pad, method = "both", p=0.5,                             N=NROW(data_pad), seed = 125)$data
 dim(data_pad_balance)
```

## Converting predictors to category
```{r,message=FALSE, warning=FALSE, echo= F}
data_pad_balance <- data_pad_balance %>%
   mutate(across(everything(), as.factor))
```

## Partitioning data set
```{r,message=FALSE, warning=FALSE, echo= F}
# PARTITION DATA
set.seed(123)
intrain <- createDataPartition(y=1:NROW(data_pad_balance), p= 0.67, list = FALSE)
training <- data_pad_balance[intrain,];  testing <- data_pad_balance[-intrain,]

dim(training) # training data
dim(testing)
```

The training data has 76 observations with 1887 now (old =1057 when compared) variables.
The testing data has 32 observation with 1887 now (old= 1057 when compared) variables.



## Model fitting 

```{r}
#------ Model building -----------
# Create a wrapper function to abstract away the common aspects of model fitting
formula<- FI_q30~.
fit.model <- function(method, tunegrid="", data=NULL, formula=NULL) {
  
  data <- training
  if(is.null(formula)) formula<- FI_q30~.
  
  # Train the model
   train(
           formula,
           data = data,
           method = method,
           trControl = trainControl(method = "cv", 5),
           preProcess = c("center","scale"),
           tuneGrid = tunegrid)
          
}
```

```{r}
# Logistic Regression
log <-train(formula,
                 data=training,
                 method="glm",
                 family = binomial(link = "logit"),
                trControl = trainControl(method = "cv", 5),
                preProcess = c("center", "scale")) 
```

```{r}
# LDA
lda <- train(formula,
                 data=training,
                 method="lda",
                trControl = trainControl(method = "cv", 5),
                preProcess = c("center", "scale"))

```


```{r}
#-------------- Elastic Net Models -------------------
# fit a LASSO model
lasso <- fit.model("glmnet", expand.grid(.alpha=1, .lambda=seq(0,0.1,0.01)))

# Fit a Ridge regression model
ridge <- fit.model("glmnet", expand.grid(.alpha=0, .lambda=seq(0,0.1,0.01)))

```

```{r}
# Bagging
# bag <- fit.model("rf", data.frame(mtry=11))
bag <- train(formula,
                 data=training,
                 method="rf",
                trControl = trainControl(method = "cv", 5),
                preProcess = c("center", "scale"),
                tuneGrid = data.frame(mtry=11),
                ntree = 1000) 

```

```{r}
# Random Forest
# rf <- fit.model("rf", data.frame(mtry=1:10))
# rf <- train(formula,
#                  data=training,
#                  method="rf",
#                 trControl = trainControl(method = "cv", 5),
#                 preProcess = c("center", "scale"),
#                 tuneGrid = data.frame(mtry=1:10),
#                 ntree = 1000) 

```

```{r}
#-------------- 

# Support Vector Machine with linear kernel
set.seed(125)
trctrl <- trainControl(method = "cv", number=5)
svc <- train(formula, data = training, method = "svmLinear",
                    trControl=trctrl, prob.model=T,
                    tuneLength = 10)

```

```{r}
# Support Vector Machine with radial kernel
set.seed(125)
trctrl <- trainControl(method = "cv", number=5)
svmR <- train(formula , data = training, method = "svmRadial",
                    trControl=trctrl, prob.model=T,
                    tuneLength = 10)
```


## Making predictions 

```{r}
# pred <- function(model){
#   model <- lasso
#     pred.test<- predict(model, testing)
#     misscal<- round(mean(pred.test != testing$FI_q30),digits = 2)
#     
#    #  test_pred_1 <- predict(model, newdata = testing, type= "prob")
#    #  ROC_SR <- roc(testing$FI_q30, predictor = test_pred_1[,2])
#    #  # # plot(ROC_SR, col="brown")
#    #  AUC<-round(ROC_SR$auc, digits=4)*100  # AUC
#    #  # text(x=0.4, y=0.25, paste("Area Under Curve = ", AUC, sep=""), col="blue", cex=1.2)
#    # AUC  = 0
#   return(list(missclass=misscal))
#}
```

Metrics
```{r}
library(mlr3measures)
# Create a custom confusion matrix with performance metrics
metrics <- function(model_object, response="", test_data=NULL) {
  # response = "FI_q30"
  # model_object <- log
  # 
  if(is.null(test_data)) test_data <- testing
  
  # make predictions
  prediction <- predict(model_object, test_data) 
  
  target <- test_data[, response]
  
  cmat <- confusionMatrix(prediction, target, mode = "prec_recall")
  
  misscal<- round(mean(prediction != target),digits = 2)
  
 # Returned outputs
 return(list(
   accuracy = (1-misscal),
   mcr = misscal,
   sens = round(cmat$byClass[1],2),
   spec = round(cmat$byClass[2],2),
   fbeta = round(cmat$byClass[7],2)
 ))
  
}
```

```{r}
metric_log <- metrics(lasso, response = "FI_q30")
#------- Compute performance metrics for the full models ---------------
log.metric <- metrics(log, response = "FI_q30")
lda.metric <- metrics(lda, response = "FI_q30")
# knn.metric <- metrics(knn)
lasso.metric <- metrics(lasso, response = "FI_q30")
ridge.metric <- metrics(ridge, response = "FI_q30")
bag.metric <- metrics(bag, response = "FI_q30")
# rf.metric <- metrics(rf)
svc.metric <- metrics(svc, response = "FI_q30")
# svmP.metric <- metrics(svmP)
svmR.metric <- metrics(svmR, response = "FI_q30")

mod.sum <- data.frame(rbind(
                          c("Logistic", log.metric$mcr, log.metric$accuracy, log.metric$sens, log.metric$spec, log.metric$fbeta),
                          c("LDA",  lda.metric$mcr, lda.metric$accuracy, lda.metric$sens, lda.metric$spec, lda.metric$fbeta),
                          c("LASSO", lasso.metric$mcr, lasso.metric$accuracy, lasso.metric$sens, lasso.metric$spec, lasso.metric$fbeta),
                          c("Ridge", ridge.metric$mcr, ridge.metric$accuracy, ridge.metric$sens, ridge.metric$spec, ridge.metric$fbeta),
                          c("Bagging", bag.metric$mcr, bag.metric$accuracy, bag.metric$sens, bag.metric$spec, bag.metric$fbeta),
                          c("SVC",  svc.metric$mcr, svc.metric$accuracy, svc.metric$sens, svc.metric$spec, svc.metric$fbeta),
                          c("SVM (Radial Kernel)", svmR.metric$mcr, svmR.metric$accuracy, svmR.metric$sens, svmR.metric$spec, svmR.metric$fbeta)))

names(mod.sum) <- c("Model", "Misclassification Rate", "Accuracy", "Sensitivity", "Specificity", "fbeta")

kable(mod.sum, align = "lccccc", caption = "Table : Evaluation metrics for Housing Insecurity with Permanent Address as a response") %>%
  kable_paper("hover", full_width = F)%>% 
       kable_styling(font_size = 12)

```
Base on our table of results SVM with radial basis function is the best 

```{r}

Var <- varImp(svmR, scale = FALSE)
plot(Var)

```




























